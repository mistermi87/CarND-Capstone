{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files from the source dirs to a unified data directory\n",
    "data_dir = 'all_data'\n",
    "filenames = data_dir + '/filename_list.txt'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "filelist = []\n",
    "\n",
    "source_dirs = ['bosch_mini', 'sim', 'rosbag']\n",
    "for source_dir in source_dirs:\n",
    "\n",
    "    # Read source filename_list.txt\n",
    "    source_filenames = open(source_dir + '_data/filename_list.txt', 'r').read().split('\\n')\n",
    "    source_filenames.remove('')\n",
    "\n",
    "    # copying image + annotation files\n",
    "    for f in source_filenames:\n",
    "        try:\n",
    "            # copy image\n",
    "            src = source_dir + '_data/images/' + f + '.jpg'\n",
    "            dst = 'all_data/images/' + source_dir + '_' + f + '.jpg'\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        except:\n",
    "            print(\"Error: {} -- file not found\".format(source_dir + '_data/images/' + f + '.jpg') )\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            src = source_dir + '_data/annotations/' + f + '.xml'\n",
    "            dst = 'all_data/annotations/' + source_dir + '_' + f + '.xml'\n",
    "\n",
    "            # copy annotation and also modify the filename reference in the xml\n",
    "            xml_content = open(src, 'r').read()\n",
    "            repl_src = '<filename>' + f + '.jpg</filename>'\n",
    "            repl_dst = '<filename>' + source_dir + '_' + f + '.jpg</filename>'\n",
    "            xml_content = xml_content.replace(repl_src, repl_dst)\n",
    "            \n",
    "            fh = open(dst, \"w\") \n",
    "            fh.write(xml_content)\n",
    "            fh.close()\n",
    "\n",
    "        except:\n",
    "            print(\"Error: {} -- file not found\".format(source_dir + '_data/annotations/' + f + '.xml') )\n",
    "            continue\n",
    "\n",
    "        filelist.append(source_dir + '_' + f)\n",
    "\n",
    "# dumping unified filenames\n",
    "with open(filenames, mode='wt', encoding='utf-8') as myfile:\n",
    "    myfile.write('\\n'.join(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  7518\n"
     ]
    }
   ],
   "source": [
    "# usage: put this Jupyter notebook in the same directory as the train+valid dataset \n",
    "# set val_percent and run.  \n",
    "\n",
    "# data_dir = 'rosbag_data' # directory for train + val data \n",
    "# data_dir = 'bosch_mini_data' # directory for train + val data \n",
    "# data_dir = 'sim_data' # directory for train + val data\n",
    "data_dir = 'all_data' # directory for train + val data\n",
    "filename = data_dir+'/filename_list.txt' # file names are in it \n",
    "val_percent = 0.2 # percentage of validation set \n",
    "random.seed(1789) # random seed\n",
    "# read all the file names  and randomize \n",
    "filename_trainval = open(filename,'r').read().split('\\n')\n",
    "# filename_trainval.remove('')\n",
    "random.shuffle(filename_trainval) # randomize \n",
    "n_samples = len(filename_trainval) \n",
    "print(\"number of samples: \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in training set: 6015\n",
      "number of samples in validation set: 1503\n"
     ]
    }
   ],
   "source": [
    "# create list of file names for  validation set\n",
    "filename_val = random.sample(filename_trainval, int(val_percent*n_samples))\n",
    "# create list of file names for training set \n",
    "filename_train= [f for f in filename_trainval if f not in filename_val]\n",
    "\n",
    "print(\"number of samples in training set:\", len(filename_train))\n",
    "print(\"number of samples in validation set:\", len(filename_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder for training and validation sets, \n",
    "# and put image and annotation files \n",
    "\n",
    "for set_ in ['train', 'val']:\n",
    "    \n",
    "    # createa a directory and subdirectory `images`, `annotations`\n",
    "    set_dir = data_dir+'_'+set_\n",
    "    if not os.path.exists(set_dir):\n",
    "        os.makedirs(set_dir)\n",
    "    annotation_dir = set_dir+'/annotations'\n",
    "    image_dir = set_dir+'/images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    if not os.path.exists(annotation_dir):\n",
    "        os.makedirs(annotation_dir)\n",
    "        \n",
    "    if set_ == 'train':\n",
    "        filename_set = filename_train\n",
    "    elif set_ == 'val':\n",
    "        filename_set = filename_val\n",
    "        \n",
    "    # create text file listing file names \n",
    "    with open(set_dir+'/filename_list.txt', 'w') as fl:  \n",
    "\n",
    "        for f in filename_set:\n",
    "            fl.write('%s\\n' % f)\n",
    "\n",
    "    fl.close()\n",
    "\n",
    "    # copy image files \n",
    "    for f in filename_set:\n",
    "        image_name = f+'.jpg'\n",
    "        shutil.copyfile(data_dir+'/images/'+image_name, image_dir+'/'+image_name)\n",
    "\n",
    "    # copy annotation files \n",
    "    for f in filename_set:\n",
    "        annotation_name = f+'.xml'\n",
    "        shutil.copyfile(data_dir+'/annotations/'+annotation_name, annotation_dir+'/'+annotation_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
